import streamlit as st
from datetime import datetime
from zoneinfo import ZoneInfo
import requests
import zipfile
from io import BytesIO
from io import StringIO

from utils.auth import verify_token
from utils.r2 import generate_presigned_pdf_url
import csv
import pandas as pd


# =================================================
# Page Config (âš ï¸ ë°˜ë“œì‹œ ìµœìƒë‹¨, 1íšŒë§Œ)
# =================================================
st.set_page_config(
    page_title="ê´€ë¦¬ì Â· ë°œí–‰ ëŒ€ì‹œë³´ë“œ",
    layout="wide",
)

st.title("ğŸ›  ê´€ë¦¬ì í˜ì´ì§€")
st.caption("ê´€ë¦¬ì ì „ìš© ë°œí–‰ ê´€ë¦¬ í™”ë©´ì…ë‹ˆë‹¤.")


# =================================================
# 0ï¸âƒ£ ê´€ë¦¬ì ì¸ì¦
# =================================================
token = st.query_params.get("token")

if not token:
    st.error("âŒ ê´€ë¦¬ì í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
    st.info("ì •ìƒì ì¸ ê´€ë¦¬ì ë§í¬ë¡œ ì ‘ì†í•´ ì£¼ì„¸ìš”.")
    st.stop()

if isinstance(token, list):
    token = token[0]

try:
    admin = verify_token(token)
except Exception as e:
    st.error("âŒ ê´€ë¦¬ì ì¸ì¦ ì‹¤íŒ¨")
    st.code(str(e))
    st.stop()

if admin.get("role") != "admin":
    st.error("âŒ ê´€ë¦¬ì ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

kst_now = datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y-%m-%d %H:%M")
st.success(f"ê´€ë¦¬ì ë¡œê·¸ì¸ ì„±ê³µ: {admin['name']}")
st.caption(f"ê¸°ì¤€ ì‹œê°(KST): {kst_now}")

st.divider()


# =================================================
# D1 Query Helper
# =================================================
def d1_query(sql: str, params: list):
    url = (
        f"https://api.cloudflare.com/client/v4/accounts/"
        f"{st.secrets['CF_ACCOUNT_ID']}/d1/database/"
        f"{st.secrets['D1_DATABASE_ID']}/query"
    )
    headers = {
        "Authorization": f"Bearer {st.secrets['CF_API_TOKEN']}",
        "Content-Type": "application/json",
    }

    r = requests.post(
        url,
        headers=headers,
        json={"sql": sql, "params": params},
        timeout=30,
    )
    r.raise_for_status()
    data = r.json()
    return data["result"][0]["results"] if data.get("result") else []

def build_issue_log_csv(issues: list[dict]) -> bytes:
    """
    ì¡°íšŒëœ ë°œí–‰ ëª©ë¡ ê¸°ì¤€ ë¡œê·¸ CSV ìƒì„± (ì •ìƒ ì§‘ê³„ ë²„ì „)
    """
    if not issues:
        return b""

    codes = [r["compliance_code"] for r in issues]
    placeholders = ",".join(["?"] * len(codes))

    sql = f"""
    SELECT
      i.compliance_code,
      i.fc_name,
      i.customer_name,
      i.customer_age_band,
      i.created_at,

      -- âœ… ë¯¸ë¦¬ë³´ê¸° ìˆ˜: FC ê¸°ì¤€ Â· í•˜ë£¨ 1íšŒ
      COUNT(
        DISTINCT
        CASE
          WHEN e.event_type = 'view'
           AND e.actor_type = 'fc'
          THEN e.actor_id || DATE(e.created_at, '+9 hours')
        END
      ) AS view_cnt,

      -- âœ… ë‹¤ìš´ë¡œë“œ ìˆ˜: FC ê¸°ì¤€ ì „ì²´
      COUNT(
        CASE
          WHEN e.event_type LIKE '%download%'
           AND e.actor_type = 'fc'
          THEN 1
        END
      ) AS download_cnt,

      -- âœ… ìµœê·¼ ë¯¸ë¦¬ë³´ê¸° ì‹œê° (FC ê¸°ì¤€)
      MAX(
        CASE
          WHEN e.event_type = 'view'
           AND e.actor_type = 'fc'
          THEN e.created_at
        END
      ) AS last_view_at

    FROM report_issue i
    LEFT JOIN report_issue_event e
      ON i.compliance_code = e.compliance_code
    WHERE i.compliance_code IN ({placeholders})
    GROUP BY
      i.compliance_code,
      i.fc_name,
      i.customer_name,
      i.customer_age_band,
      i.created_at
    ORDER BY i.created_at DESC;
    """

    rows = d1_query(sql, codes)

    buf = StringIO()
    writer = csv.writer(buf)

    writer.writerow([
        "ì‹¬ì˜ë²ˆí˜¸",
        "FCëª…",
        "ê³ ê°ëª…",
        "ì—°ë ¹ëŒ€",
        "ë°œí–‰ì¼ì‹œ",
        "ë¯¸ë¦¬ë³´ê¸° ìˆ˜",
        "ë‹¤ìš´ë¡œë“œ ìˆ˜",
        "ìµœê·¼ ë¯¸ë¦¬ë³´ê¸° ì‹œê°",
    ])

    for r in rows:
        writer.writerow([
            r["compliance_code"],
            r["fc_name"],
            r["customer_name"] or "",
            r["customer_age_band"],
            r["created_at"],
            r["view_cnt"],
            r["download_cnt"],
            r["last_view_at"] or "",
        ])

    return buf.getvalue().encode("utf-8-sig")  # ì—‘ì…€ í•œê¸€ ê¹¨ì§ ë°©ì§€


def build_zip_from_issues(issues):
    zip_buf = BytesIO()
    with zipfile.ZipFile(zip_buf, "w", zipfile.ZIP_DEFLATED) as z:
        for r in issues:
            signed_url = generate_presigned_pdf_url(r["pdf_r2_key"])
            resp = requests.get(signed_url, timeout=30)
            if resp.ok:
                z.writestr(r["pdf_filename"], resp.content)
    zip_buf.seek(0)
    return zip_buf.getvalue()

# =================================================
# 1ï¸âƒ£ KPI ìš”ì•½
# =================================================
sql_kpi = """
SELECT
  COUNT(*) AS total_cnt,
  COUNT(DISTINCT fc_id) AS fc_cnt,
  SUM(
    CASE WHEN DATE(created_at) = DATE('now', '+9 hours')
    THEN 1 ELSE 0 END
  ) AS today_cnt,
  MAX(created_at) AS last_issue_at
FROM report_issue;
"""
kpi = d1_query(sql_kpi, [])

c1, c2, c3, c4 = st.columns(4)
c1.metric("ğŸ“„ ì „ì²´ ë°œí–‰ ìˆ˜", f"{kpi[0]['total_cnt']:,}")
c2.metric("ğŸ‘¤ ì°¸ì—¬ FC ìˆ˜", f"{kpi[0]['fc_cnt']:,}")
c3.metric("ğŸ—“ ì˜¤ëŠ˜ ë°œí–‰", f"{kpi[0]['today_cnt']:,}")
c4.metric("â± ìµœê·¼ ë°œí–‰", kpi[0]["last_issue_at"][:16])

st.divider()


# =================================================
# 2ï¸âƒ£ í•„í„°
# =================================================
st.subheader("ğŸ” ë°œí–‰ ëª©ë¡ í•„í„°")

f1, f2, f3, f4, f5, f6 = st.columns([2, 2, 1.5, 1.5, 1.5, 1])

with f1:
    fc_name = st.text_input("FC ì´ë¦„")

with f2:
    customer_name = st.text_input("ê³ ê°ëª…")  # âœ… ì¶”ê°€

with f3:
    age_band = st.selectbox(
        "ì—°ë ¹ëŒ€",
        ["ì „ì²´", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€", "70ëŒ€"],
    )

with f4:
    date_from = st.date_input("ì‹œì‘ì¼")

with f5:
    date_to = st.date_input("ì¢…ë£Œì¼")   # âœ… ì´ê²ƒë§Œ ì¶”ê°€

with f6:
    st.markdown("<br>", unsafe_allow_html=True)  # ğŸ”‘ ë¼ë²¨ ë†’ì´ ë§ì¶”ê¸°
    search_clicked = st.button("ğŸ” ì¡°íšŒ", use_container_width=True)

where = ["1=1"]
params = []

if fc_name:
    where.append("fc_name LIKE ?")
    params.append(f"%{fc_name}%")

if customer_name:  # âœ… ì¶”ê°€
    where.append("customer_name LIKE ?")
    params.append(f"%{customer_name}%")

if age_band != "ì „ì²´":
    where.append("customer_age_band = ?")
    params.append(age_band)

if date_from:
    where.append("DATE(created_at) >= ?")
    params.append(str(date_from))

if date_to:
    where.append("DATE(created_at) <= ?")
    params.append(str(date_to))

if date_from and date_to and date_from > date_to:
    st.warning("ì¢…ë£Œì¼ì€ ì‹œì‘ì¼ ì´í›„ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

# ==========================
# ì¡°íšŒ ë²„íŠ¼
# ==========================
if "searched" not in st.session_state:
    st.session_state["searched"] = False

if search_clicked:
    st.session_state["searched"] = True

if not st.session_state["searched"]:
    st.info("ì¡°ê±´ì„ ì…ë ¥í•œ í›„ [ì¡°íšŒ] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
    st.stop()

# =================================================
# 3ï¸âƒ£ ë°œí–‰ ëª©ë¡ ì¡°íšŒ
# =================================================
sql_list = f"""
SELECT
  compliance_code,
  fc_name,
  customer_name,
  customer_age_band,
  created_at,
  pdf_r2_key,
  pdf_filename
FROM report_issue
WHERE {' AND '.join(where)}
ORDER BY created_at DESC
LIMIT 200;
"""

rows = d1_query(sql_list, params)

st.subheader("ğŸ“‹ ë°œí–‰ ëª©ë¡")

if not rows:
    st.info("ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()


# =================================================
# 4ï¸âƒ£ ë°œí–‰ ëª©ë¡ í…Œì´ë¸”
# =================================================
for r in rows:
    with st.container(border=True):
        c1, c2, c3, c4, c5, c6 = st.columns([3, 2, 2, 2, 1, 1])

        c1.markdown(f"**{r['compliance_code']}**")
        c2.write(r["fc_name"])
        c3.write(r["customer_name"] or "-")
        c4.write(r["customer_age_band"])

        with c5:
            detail_url = (
                f"/admin_detail"
                f"?code={r['compliance_code']}"
                f"&token={token}"
            )
            st.link_button("ìƒì„¸", detail_url)

        with c6:
            pdf_url = generate_presigned_pdf_url(r["pdf_r2_key"])
            st.link_button(
                "PDF",
                pdf_url,
                use_container_width=True,
            )

st.divider()


# =================================================
# 5ï¸âƒ£ ì¼ê´„ ë‹¤ìš´ë¡œë“œ (ZIP)
# =================================================
st.subheader("ğŸ“¦ ì¼ê´„ ë‹¤ìš´ë¡œë“œ")

ts = datetime.now(ZoneInfo("Asia/Seoul")).strftime("%Y%m%d_%H%M")

col_a, col_b = st.columns(2)

with col_a:
    if st.button("ğŸ“„ ì¡°íšŒ ê²°ê³¼ PDF ZIP ë‹¤ìš´ë¡œë“œ"):
        with st.spinner("PDF ZIP ìƒì„± ì¤‘..."):
            zip_bytes = build_zip_from_issues(rows)

            st.download_button(
                label="ğŸ“¥ PDF ZIP ë‹¤ìš´ë¡œë“œ",
                data=zip_bytes,
                file_name=f"reports_{ts}.zip",
                mime="application/zip",
            )

with col_b:
    if st.button("ğŸ“Š ë°œí–‰ ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ"):
        csv_bytes = build_issue_log_csv(rows)

        st.download_button(
            label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_bytes,
            file_name=f"report_logs_{ts}.csv",
            mime="text/csv",
        )

st.divider()


# =================================================
# 6ï¸âƒ£ í†µê³„ ì°¨íŠ¸
# =================================================

df = pd.DataFrame(rows)

# ğŸ”‘ í•µì‹¬: errors="coerce" + format ëª…ì‹œ
df["created_at_dt"] = pd.to_datetime(
    df["created_at"],
    errors="coerce",
    format="%Y-%m-%d %H:%M:%S",
)

# NaT ì œê±°
df = df.dropna(subset=["created_at_dt"])

df["created_date"] = df["created_at_dt"].dt.date

daily_df = (
    df.groupby("created_date")
      .size()
      .reset_index(name="cnt")
      .sort_values("created_date")
)

if daily_df.empty:
    st.info("ì¡°íšŒ ê²°ê³¼ ê¸°ì¤€ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
elif len(daily_df) == 1:
    # í•˜ë£¨ë§Œ ìˆì„ ë•Œ â†’ ë§‰ëŒ€ ê·¸ë˜í”„
    st.bar_chart(
        daily_df,
        x="created_date",
        y="cnt",
        use_container_width=True,
    )
else:
    # ì—¬ëŸ¬ ë‚  â†’ ì„  ê·¸ë˜í”„
    st.line_chart(
        daily_df,
        x="created_date",
        y="cnt",
        use_container_width=True,
    )
